{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925fd810",
   "metadata": {},
   "source": [
    "0. Imports and Random Seed setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c77578a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20af0597010>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434405f",
   "metadata": {},
   "source": [
    "1. Data Loading and Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95b689be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(root = '../data',train = True,download= True)\n",
    "test_data = torchvision.datasets.MNIST(root = '../data',train = False,download=True)\n",
    "#Has been ran once to obtain and store data, now download paramter has been changed to False\n",
    "\n",
    "x_train = train_data.data.float() / 255 #Normalising Greyscale Image Pixel Intesity\n",
    "y_train = train_data.targets\n",
    "\n",
    "x_test = test_data.data.float() / 255\n",
    "y_test = test_data.targets\n",
    "\n",
    "x_train = x_train.view(-1,28*28)\n",
    "x_test = x_test.view(-1,28*28)  #Flattens the images to 2d, could use -1 or 60_000 and 10_000\n",
    "\n",
    "def one_hot(labels,num_classes = 10):\n",
    "    output = torch.zeros(labels.size(0),num_classes)\n",
    "    row = torch.arange(labels.size(0))\n",
    "    output[row,labels] = 1.0\n",
    "    return output\n",
    "#One hot encode label data so it can be usefully analysed\n",
    "\n",
    "y_test_oh = one_hot(y_test,10)\n",
    "y_train_oh = one_hot(y_train,10)\n",
    "\n",
    "def get_batches(x,y,batch_size = 64):\n",
    "    idx = torch.randperm(x.size(0))\n",
    "    for i in range(0,x.size(0),batch_size):\n",
    "        batches_idx = idx[i:i+batch_size]\n",
    "        yield x[batches_idx],y[batches_idx]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7be31c6",
   "metadata": {},
   "source": [
    "2. Building and Training MLP without High Level help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f233c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_of_pred(probs,y_oh):\n",
    "    predicted = torch.argmax(probs,dim = 1)\n",
    "    true_classes = torch.argmax(y_oh,dim = 1)\n",
    "    correct = (predicted == true_classes).float()\n",
    "    accuracy = correct.mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6653fc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg loss = 15.6582\n",
      "Accuracy on Epoch 1 : 0.2758333384990692\n",
      "Epoch 2: avg loss = 13.5688\n",
      "Accuracy on Epoch 2 : 0.44795000553131104\n",
      "Epoch 3: avg loss = 11.9998\n",
      "Accuracy on Epoch 3 : 0.565416693687439\n",
      "Epoch 4: avg loss = 10.6455\n",
      "Accuracy on Epoch 4 : 0.659166693687439\n",
      "Epoch 5: avg loss = 9.6828\n",
      "Accuracy on Epoch 5 : 0.7016666531562805\n",
      "Epoch 6: avg loss = 9.0084\n",
      "Accuracy on Epoch 6 : 0.715149998664856\n",
      "Epoch 7: avg loss = 8.5093\n",
      "Accuracy on Epoch 7 : 0.721916675567627\n",
      "Epoch 8: avg loss = 8.1235\n",
      "Accuracy on Epoch 8 : 0.7268333435058594\n",
      "Epoch 9: avg loss = 7.8148\n",
      "Accuracy on Epoch 9 : 0.7305333614349365\n",
      "Epoch 10: avg loss = 7.5620\n",
      "Accuracy on Epoch 10 : 0.7340333461761475\n",
      "Epoch 11: avg loss = 7.3503\n",
      "Accuracy on Epoch 11 : 0.7364833354949951\n",
      "Epoch 12: avg loss = 7.1703\n",
      "Accuracy on Epoch 12 : 0.7383166551589966\n",
      "Epoch 13: avg loss = 7.0148\n",
      "Accuracy on Epoch 13 : 0.7401999831199646\n",
      "Epoch 14: avg loss = 6.8789\n",
      "Accuracy on Epoch 14 : 0.7421833276748657\n",
      "Epoch 15: avg loss = 6.7592\n",
      "Accuracy on Epoch 15 : 0.743066668510437\n",
      "Epoch 16: avg loss = 6.6527\n",
      "Accuracy on Epoch 16 : 0.7445666790008545\n",
      "Epoch 17: avg loss = 6.5570\n",
      "Accuracy on Epoch 17 : 0.7454833388328552\n",
      "Epoch 18: avg loss = 6.4706\n",
      "Accuracy on Epoch 18 : 0.745983362197876\n",
      "Epoch 19: avg loss = 6.3921\n",
      "Accuracy on Epoch 19 : 0.7465999722480774\n",
      "Epoch 20: avg loss = 6.3202\n",
      "Accuracy on Epoch 20 : 0.7472000122070312\n",
      "Epoch 21: avg loss = 6.2537\n",
      "Accuracy on Epoch 21 : 0.7474833130836487\n",
      "Epoch 22: avg loss = 6.1541\n",
      "Accuracy on Epoch 22 : 0.7639333605766296\n",
      "Epoch 23: avg loss = 6.0343\n",
      "Accuracy on Epoch 23 : 0.7953000068664551\n",
      "Epoch 24: avg loss = 5.9182\n",
      "Accuracy on Epoch 24 : 0.8043166399002075\n",
      "Epoch 25: avg loss = 5.8075\n",
      "Accuracy on Epoch 25 : 0.8062999844551086\n",
      "Epoch 26: avg loss = 5.6798\n",
      "Accuracy on Epoch 26 : 0.8198666572570801\n",
      "Epoch 27: avg loss = 5.5208\n",
      "Accuracy on Epoch 27 : 0.8615833520889282\n",
      "Epoch 28: avg loss = 5.3647\n",
      "Accuracy on Epoch 28 : 0.871999979019165\n",
      "Epoch 29: avg loss = 5.2142\n",
      "Accuracy on Epoch 29 : 0.8762500286102295\n",
      "Epoch 30: avg loss = 5.0698\n",
      "Accuracy on Epoch 30 : 0.8788666725158691\n",
      "Epoch 31: avg loss = 4.9317\n",
      "Accuracy on Epoch 31 : 0.8791666626930237\n",
      "Epoch 32: avg loss = 4.7998\n",
      "Accuracy on Epoch 32 : 0.8809499740600586\n",
      "Epoch 33: avg loss = 4.6740\n",
      "Accuracy on Epoch 33 : 0.8821666836738586\n",
      "Epoch 34: avg loss = 4.5542\n",
      "Accuracy on Epoch 34 : 0.8823166489601135\n",
      "Epoch 35: avg loss = 4.4401\n",
      "Accuracy on Epoch 35 : 0.883733332157135\n",
      "Epoch 36: avg loss = 4.3316\n",
      "Accuracy on Epoch 36 : 0.8835166692733765\n",
      "Epoch 37: avg loss = 4.2282\n",
      "Accuracy on Epoch 37 : 0.8858833312988281\n",
      "Epoch 38: avg loss = 4.1297\n",
      "Accuracy on Epoch 38 : 0.887666642665863\n",
      "Epoch 39: avg loss = 4.0357\n",
      "Accuracy on Epoch 39 : 0.8877500295639038\n",
      "Epoch 40: avg loss = 3.9461\n",
      "Accuracy on Epoch 40 : 0.8889333605766296\n",
      "Epoch 41: avg loss = 3.8606\n",
      "Accuracy on Epoch 41 : 0.89041668176651\n",
      "Epoch 42: avg loss = 3.7789\n",
      "Accuracy on Epoch 42 : 0.8911499977111816\n",
      "Epoch 43: avg loss = 3.7007\n",
      "Accuracy on Epoch 43 : 0.8924000263214111\n",
      "Epoch 44: avg loss = 3.6259\n",
      "Accuracy on Epoch 44 : 0.894266664981842\n",
      "Epoch 45: avg loss = 3.5542\n",
      "Accuracy on Epoch 45 : 0.8945666551589966\n",
      "Epoch 46: avg loss = 3.4855\n",
      "Accuracy on Epoch 46 : 0.8960166573524475\n",
      "Epoch 47: avg loss = 3.4196\n",
      "Accuracy on Epoch 47 : 0.8965333104133606\n",
      "Epoch 48: avg loss = 3.3563\n",
      "Accuracy on Epoch 48 : 0.8977000117301941\n",
      "Epoch 49: avg loss = 3.2955\n",
      "Accuracy on Epoch 49 : 0.897599995136261\n",
      "Epoch 50: avg loss = 3.2370\n",
      "Accuracy on Epoch 50 : 0.8985333442687988\n",
      "Epoch 51: avg loss = 3.1808\n",
      "Accuracy on Epoch 51 : 0.9007166624069214\n",
      "Epoch 52: avg loss = 3.1266\n",
      "Accuracy on Epoch 52 : 0.9007499814033508\n",
      "Epoch 53: avg loss = 3.0743\n",
      "Accuracy on Epoch 53 : 0.9018166661262512\n",
      "Epoch 54: avg loss = 3.0239\n",
      "Accuracy on Epoch 54 : 0.9022833108901978\n",
      "Epoch 55: avg loss = 2.9753\n",
      "Accuracy on Epoch 55 : 0.9027666449546814\n",
      "Epoch 56: avg loss = 2.9284\n",
      "Accuracy on Epoch 56 : 0.9031999707221985\n",
      "Epoch 57: avg loss = 2.8831\n",
      "Accuracy on Epoch 57 : 0.9037666916847229\n",
      "Epoch 58: avg loss = 2.8393\n",
      "Accuracy on Epoch 58 : 0.9053000211715698\n",
      "Epoch 59: avg loss = 2.7969\n",
      "Accuracy on Epoch 59 : 0.9052000045776367\n",
      "Epoch 60: avg loss = 2.7558\n",
      "Accuracy on Epoch 60 : 0.9062666893005371\n"
     ]
    }
   ],
   "source": [
    "w1 = torch.randn(28*28,64,requires_grad= True)\n",
    "w2 = torch.randn(64,10,requires_grad= True)\n",
    "b1 = torch.randn(64,requires_grad= True)\n",
    "b2 = torch.randn(10,requires_grad= True)\n",
    "\n",
    "epoch_n = 60\n",
    "running_loss = 0.0\n",
    "batch_count = 0\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "for i in range(1,epoch_n+1):\n",
    "    epoch_probs = []\n",
    "    epoch_ys = []\n",
    "    for x,y in get_batches(x_train,y_train_oh):\n",
    "        z1 = x @ w1 + b1\n",
    "        relu = torch.maximum(z1,torch.zeros_like(z1))\n",
    "        z2 = relu @ w2 + b2\n",
    "        \n",
    "        probs = torch.softmax(z2,dim = 1)\n",
    "        shift = 1e-10 #Prevent taking log of 0 choose small shift to minimally effect results\n",
    "        class_probs = torch.sum(probs * y,dim= 1)\n",
    "        cross_entropy = -torch.log(class_probs + shift)\n",
    "        loss = cross_entropy.mean()\n",
    "        \n",
    "        epoch_probs.append(probs.detach())\n",
    "        epoch_ys.append(y.detach())\n",
    "        \n",
    "        loss.backward()\n",
    "        batch_count +=1\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            w1 -= learning_rate * w1.grad\n",
    "            w2 -= learning_rate * w2.grad\n",
    "            b1 -= learning_rate * b1.grad\n",
    "            b2 -= learning_rate * b2.grad #Note to self must be done in place for requires_grad = True to stay\n",
    "        \n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "        b1.grad.zero_()\n",
    "        b2.grad.zero_()\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {i}: avg loss = {running_loss / batch_count:.4f}\")\n",
    "    all_probs = torch.cat(epoch_probs,dim=0)\n",
    "    all_ys = torch.cat(epoch_ys,dim = 0)\n",
    "    print(f'Accuracy on Epoch {i} : {accuracy_of_pred(all_probs,all_ys)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14415dd",
   "metadata": {},
   "source": [
    "Evaluating on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44fee889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046000242233276\n"
     ]
    }
   ],
   "source": [
    "probs = []\n",
    "ys= []\n",
    "\n",
    "for x,y in get_batches(x_test,y_test_oh):\n",
    "        z1 = x @ w1 + b1\n",
    "        relu = torch.maximum(z1,torch.zeros_like(z1))\n",
    "        z2 = relu @ w2 + b2\n",
    "        preds = torch.softmax(z2,dim = 1)\n",
    "        class_probs = torch.sum(preds * y,dim= 1)\n",
    "        \n",
    "        probs.append(preds.detach())\n",
    "        ys.append(y.detach())\n",
    "        \n",
    "probs = torch.cat(probs,dim=0)\n",
    "ys = torch.cat(ys,dim = 0)       \n",
    "print(accuracy_of_pred(probs,ys).item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
